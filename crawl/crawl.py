import time
import csv
import logging
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager

# ==============================
# è¨­å®š
# ==============================
RACE_URL = "https://race.netkeiba.com/race/shutuba.html?race_id=202505050812"
PAST_RACE_COUNT = 5
CSV_FILENAME = "shutuba_with_past5.csv"

# ==============================
# ãƒ­ã‚°è¨­å®š
# ==============================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

# ==============================
# SeleniumåˆæœŸåŒ–
# ==============================
options = Options()
options.add_argument("--start-maximized")
# options.add_argument("--headless")  # ç”»é¢ä¸è¦ãªã‚‰ON

driver = webdriver.Chrome(
    service=Service(ChromeDriverManager().install()),
    options=options
)

# ==============================
# å‡ºèµ°è¡¨å–å¾—
# ==============================
def get_shutuba_list(driver):
    logger.info("å‡ºèµ°è¡¨ãƒšãƒ¼ã‚¸ã¸ã‚¢ã‚¯ã‚»ã‚¹")
    driver.get(RACE_URL)
    time.sleep(3)

    horses = []
    rows = driver.find_elements(By.CSS_SELECTOR, "tr.HorseList")

    for idx, row in enumerate(rows, 1):
        try:
            # æ ç•ª (ä¾‹: class="Waku1")
            waku = ""
            try:
                waku = row.find_element(By.CSS_SELECTOR, 'td[class^="Waku"]').text
            except:
                logger.warning(f"{idx}è¡Œç›®: æ ç•ªå–å¾—å¤±æ•—")

            # é¦¬ç•ª (ä¾‹: class="Umaban1")
            num = ""
            try:
                num = row.find_element(By.CSS_SELECTOR, 'td[class^="Umaban"]').text
            except:
                logger.warning(f"{idx}è¡Œç›®: é¦¬ç•ªå–å¾—å¤±æ•—")

            # é¦¬å + URL
            name_tag = row.find_element(By.CSS_SELECTOR, "span.HorseName a")
            name = name_tag.text.strip()
            url = name_tag.get_attribute("href")

            # ã‚ªãƒƒã‚º
            odds = ""
            try:
                odds = row.find_element(By.CSS_SELECTOR, 'span[id^="odds-"]').text
            except:
                logger.warning(f"{idx}è¡Œç›®: ã‚ªãƒƒã‚ºå–å¾—å¤±æ•—")

            horses.append({
                "æ ç•ª": waku,
                "é¦¬ç•ª": num,
                "é¦¬å": name,
                "ã‚ªãƒƒã‚º": odds,
                "URL": url
            })

            logger.info(f"å–å¾—: æ {waku} é¦¬ç•ª{num} {name} ({odds})")

        except Exception as e:
            logger.error(f"{idx}è¡Œç›®: å‡ºèµ°è¡¨å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    logger.info(f"âœ… å‡ºèµ°é¦¬ {len(horses)} é ­å–å¾—å®Œäº†")
    return horses

# ==============================
# é¦¬è©³ç´° â†’ ç›´è¿‘ãƒ¬ãƒ¼ã‚¹å–å¾—
# ==============================
def get_recent_races(driver, horse_url, num_races=5):
    logger.info(f"è©³ç´°ãƒšãƒ¼ã‚¸é·ç§»: {horse_url}")
    driver.get(horse_url)
    time.sleep(3)

    try:
        table = driver.find_element(By.CSS_SELECTOR, "table.db_h_race_results")
    except:
        logger.error("æˆç¸¾ãƒ†ãƒ¼ãƒ–ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return []

    rows = table.find_elements(By.TAG_NAME, "tr")[1:num_races+1]
    race_data = []

    for idx, row in enumerate(rows, 1):
        cols = row.find_elements(By.TAG_NAME, "td")

        if len(cols) < 17:
            logger.warning(f"{idx}è¡Œç›®: åˆ—ä¸è¶³ã§ã‚¹ã‚­ãƒƒãƒ—")
            continue

        race_info = {
            "é–‹å‚¬": cols[1].text,
            "è·é›¢": cols[14].text,
            "é¦¬å ´": cols[16].text,
            "é€šé": cols[21].text,
            "ã‚¿ã‚¤ãƒ ": cols[18].text,
            "ä¸Šã‚Š": cols[23].text,
            "ãƒšãƒ¼ã‚¹": cols[22].text
        }

        race_data.append(race_info)

    return race_data

# ==============================
# CSVå‡ºåŠ›
# ==============================
def export_to_csv(data, filename):
    if not data:
        logger.warning("CSVã«å‡ºåŠ›ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return

    fieldnames = data[0].keys()

    with open(filename, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

    logger.info(f"âœ… CSVå‡ºåŠ›å®Œäº†: {filename}")

# ==============================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ==============================
try:
    all_results = []

    # â‘  å‡ºèµ°è¡¨å–å¾—
    horses = get_shutuba_list(driver)

    # â‘¡ é¦¬ã”ã¨ã«è©³ç´°å–å¾—
    for i, horse in enumerate(horses, 1):
        logger.info(f"====== [{i}/{len(horses)}] {horse['é¦¬å']} å‡¦ç†é–‹å§‹ ======")

        base_data = {
            "æ ç•ª": horse["æ ç•ª"],
            "é¦¬ç•ª": horse["é¦¬ç•ª"],
            "é¦¬å": horse["é¦¬å"],
            "ã‚ªãƒƒã‚º": horse["ã‚ªãƒƒã‚º"]
        }

        try:
            races = get_recent_races(driver, horse["URL"], PAST_RACE_COUNT)

            # 5èµ°æœªæº€ãªã‚‰ç©ºãƒ‡ãƒ¼ã‚¿ã§è£œå®Œ
            while len(races) < PAST_RACE_COUNT:
                races.append({
                    "é–‹å‚¬": "",
                    "è·é›¢": "",
                    "é¦¬å ´": "",
                    "é€šé": "",
                    "ã‚¿ã‚¤ãƒ ": "",
                    "ä¸Šã‚Š": "",
                    "ãƒšãƒ¼ã‚¹": ""
                })

            # æ¨ªæŒã¡å±•é–‹
            for idx, race in enumerate(races, 1):
                for key, value in race.items():
                    base_data[f"{idx}èµ°å‰_{key}"] = value

        except Exception as e:
            logger.error(f"{horse['é¦¬å']} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—: {e}")

            # å¤±æ•—æ™‚ã‚‚ç©ºã§åŸ‹ã‚ã‚‹
            for idx in range(1, PAST_RACE_COUNT + 1):
                for key in ["é–‹å‚¬", "è·é›¢", "é¦¬å ´", "é€šé", "ã‚¿ã‚¤ãƒ ", "ä¸Šã‚Š", "ãƒšãƒ¼ã‚¹"]:
                    base_data[f"{idx}èµ°å‰_{key}"] = ""

        all_results.append(base_data)
        time.sleep(1)  # ã‚µãƒ¼ãƒãƒ¼è² è·å¯¾ç­–

    # â‘¢ CSVå‡ºåŠ›
    export_to_csv(all_results, CSV_FILENAME)

    logger.info("ğŸ‰ å…¨å‡¦ç†å®Œäº†ï¼")

finally:
    driver.quit()
    logger.info("Selenium çµ‚äº†")
